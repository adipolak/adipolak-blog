<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Adi Polak</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.140.2">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    
    
      <link href="/tags/apache-spark/index.xml" rel="alternate" type="application/rss+xml" title="Adi Polak" />
      <link href="/tags/apache-spark/index.xml" rel="feed" type="application/rss+xml" title="Adi Polak" />
      
    

    
      <link rel="canonical" href="http://localhost:1313/tags/apache-spark/">
    

    <meta property="og:url" content="http://localhost:1313/tags/apache-spark/">
  <meta property="og:site_name" content="Adi Polak">
  <meta property="og:title" content="Apache Spark">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">

  <meta itemprop="name" content="Apache Spark">
  <meta itemprop="datePublished" content="2021-04-11T00:00:00+00:00">
  <meta itemprop="dateModified" content="2021-04-11T00:00:00+00:00">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Apache Spark">

	<link rel="stylesheet" href="/css/custom.css">
  </head><body class="ma0 avenir bg-near-white development">

    <header class="header bg-black text-white">
  <div class="container tc pv3 ph3 ph4-ns">
    
    <div class="site-navigation">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Adi Polak
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="about page">
              about
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/presentations/" title="presentations page">
              presentations
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/subscribe/" title="subscribe page">
              subscribe
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact-me/" title="contact page">
              contact
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>



    </div>

    
    <div class="title-section mw6 center">
      <h1 class="site-title f3 f4-l fw3 mb2 lh-title">
        Apache Spark
      </h1>
      
      
      
    </div>
  </div>
</header>

    <main class="pb7" role="main">
      
  <article class="cf pa3 pa4-m pa4-l">
    <div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray">
      <p>Below you will find pages that utilize the taxonomy term ‚ÄúApache Spark‚Äù</p>
    </div>
  </article>
  <div class="mw8 center">
    <section class="flex-ns flex-wrap justify-around mt5">
      
        <div class="relative w-100  mb4 bg-white">
          <article>
  <h2><a href="http://localhost:1313/post/data_and_ai_summit2021/">Data&#43;AI Summit 2021 is Coming</a></h2>
  <p><p>It&rsquo;s almost been half a year since the last summit.</p>
<p>Data+AI Summit 2021 starts on Monday, May 24 till Friday, May 28.
The training will be held on May 24-25 and will cater to a large set of practitioners, definitely more extensive than previous times:
Data Analyst, Data Engineer, Data Scientist, ML Engineer, Partner Data Engineer, Platform Engineer, Technical. The wide range of roles makes me curious about the various technical personas in the Data and AI space. It&rsquo;s not only Data Engineers and Data Scientists. There is a wide range of people who can benefit from attending the summit.</p></p>
  <a href="http://localhost:1313/post/data_and_ai_summit2021/" class="read-more">Read More ‚Üí</a>
</article>
        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <article>
  <h2><a href="http://localhost:1313/post/delta-lake-essential-fundamentals---part-4/">Delta Lake essential Fundamentals: Part 4 - Practical Scenarios</a></h2>
  <p><p>üéâ Welcome to the 4th part of Delta Lake essential fundamentals: the practical scenarios! üéâ</p>
<p>There are many great features that you can leverage in delta lake, from the ACID transaction, Schema Enforcement, Time Traveling, Exactly One semantic, and more.</p>
<p>Let&rsquo;s discuss two common data pipelines patterns and solutions:</p>
<h2 id="spark-structured-streaming-etl-with-deltalake-that-serves-multiple-users">Spark Structured Streaming ETL with DeltaLake that serves multiple Users</h2>
<p><strong>Spark Structured Streaming</strong>-
Apache Spark structured steaming are essentially unbounded tables of information. There is a continuous stream of data ingested into the system. As developers, we write the code to process the data continuously.
<strong>ETL</strong> stands for <strong>E</strong>xtract, <strong>T</strong>ransform and <strong>L</strong>oad.</p></p>
  <a href="http://localhost:1313/post/delta-lake-essential-fundamentals---part-4/" class="read-more">Read More ‚Üí</a>
</article>
        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <article>
  <h2><a href="http://localhost:1313/post/delta-lake-essential-fundamentals---part-3/">Delta Lake essential Fundamentals: Part 3 - compaction and checkpoint</a></h2>
  <p><p>Let&rsquo;s understand what are Delta Lake compact and checkpoint and why they are important.</p>
<h2 id="checkpoint">Checkpoint</h2>
<p>There are two known checkpoints mechanism in Apache Spark that can confuse us with DeltaLake checkpoint, so let&rsquo;s understand them and how they differ from each other:</p>
<h3 id="spark-rdd-checkpoint">Spark RDD Checkpoint</h3>
<p>Checkpoint in Spark RDD is a mechanism to persist current RDD to a file in a dedicated checkpoint directory while all references to its parent RDDs are removed.
This operation, by default, breaks data lineage when used without auditing.</p></p>
  <a href="http://localhost:1313/post/delta-lake-essential-fundamentals---part-3/" class="read-more">Read More ‚Üí</a>
</article>
        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <article>
  <h2><a href="http://localhost:1313/post/delta-lake-essential-fundamentals---the-deltalog/">Delta Lake essential Fundamentals: Part 2 - The DeltaLog</a></h2>
  <p><p>In the previous part, you learned what <a href="https://blog.adipolak.com/post/delta-lake-essential-fundamentals">ACID transactions</a> are.<br>
In this part, you will understand how Delta Transaction Log, named DeltaLog, is achieving ACID.</p>
<h2 id="transaction-log">Transaction Log</h2>
<p>A transaction log is a history of actions executed by a (TaDa üí°) database management system with the goal to guarantee <a href="https://blog.adipolak.com/post/delta-lake-essential-fundamentals/">ACID properties</a> over a crash.</p>
<h2 id="deltalake-transaction-log---detlalog">DeltaLake transaction log - DetlaLog</h2>
<p>DeltaLog is a transaction log directory that holds an <strong>ordered</strong> record of every transaction committed on a Delta Lake table since it was created.
The goal of DeltaLog is to be the <strong>single</strong> source of truth for readers who read from the same table at the same time. That means, parallel readers read the <strong>exact</strong> same data.
This is achieved by tracking all the changes that users do: read, delete, update, etc. in the DeltaLog.</p></p>
  <a href="http://localhost:1313/post/delta-lake-essential-fundamentals---the-deltalog/" class="read-more">Read More ‚Üí</a>
</article>
        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <article>
  <h2><a href="http://localhost:1313/post/delta-lake-essential-fundamentals/">Delta Lake essential Fundamentals: Part 1 - ACID</a></h2>
  <p><p>üéâ Welcome to the first part of Delta Lake essential fundamentals! üéâ</p>
<h2 id="what-is-delta-lake-">What is Delta Lake ?</h2>
<blockquote>
<p>Delta Lake is an open-source storage layer that brings ACID
transactions to Apache Spark‚Ñ¢ and big data workloads. </p>
</blockquote>
<p>DeltaLake open source consists of 3 projects:</p>
<ol>
<li><a href="https://github.com/delta-io/delta">detla</a> - Delta Lake core, written in Scala.</li>
<li><a href="https://github.com/delta-io/delta-rs">delta-rs</a> - Rust library for binding with Python and Ruby.</li>
<li><a href="https://github.com/delta-io/connectors">connectors</a> - Connectors to popular big data engines outside Spark, written mostly in Scala.</li>
</ol>
<p>Delta provides us the ability to <u>&ldquo;travel back in time&rdquo;</u> into previous versions of our data, <u>scalable metadata</u> - that means if we have a large set of raw data stored in a data lake, having metadata provides us with the flexibility needed for analytics and exploration of the data. It also provides a mechanism to <u>unify streaming and batch data</u>.<br>
<u>Schema enforcement</u> - handle schema variations to prevent insertion of bad/non-compliant records, and <u>ACID transactions</u> to ensure that the users/readers never see inconsistent data.</p></p>
  <a href="http://localhost:1313/post/delta-lake-essential-fundamentals/" class="read-more">Read More ‚Üí</a>
</article>
        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <article>
  <h2><a href="http://localhost:1313/post/apache-spark-ecosystem/">Apache Spark Ecosystem, Jan 2021 Highlights</a></h2>
  <p><p>If you&rsquo;ve been reading here for a while, you know that I&rsquo;m a big fan of Apache Spark and have been using it for more than 8 years.<br>
Apache Spark is continually growing. It started as part of the Hadoop family,<br>
but with <a href="https://medium.com/@acmurthy/hadoop-is-dead-long-live-hadoop-f22069b264ac">the slow death of hadoop</a> and the fast growth of Kubernetes, many new tools, connectors and open source have emerged.</p>
<p>Let&rsquo;s take a look at three exciting open sources:</p></p>
  <a href="http://localhost:1313/post/apache-spark-ecosystem/" class="read-more">Read More ‚Üí</a>
</article>
        </div>
      
    </section>
  </div>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  Copyright &#169; 2020 Adi Polak. All rights reserved. 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
