<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scenarios on Adi Polak</title><link>https://blog.adipolak.com/tags/scenarios/</link><description>Recent content in Scenarios on Adi Polak</description><generator>Hugo</generator><language>en-us</language><copyright>Copyright &amp;#169; 2020 Adi Polak. All rights reserved.</copyright><lastBuildDate>Mon, 22 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.adipolak.com/tags/scenarios/index.xml" rel="self" type="application/rss+xml"/><item><title>Delta Lake essential Fundamentals: Part 4 - Practical Scenarios</title><link>https://blog.adipolak.com/post/delta-lake-essential-fundamentals---part-4/</link><pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate><guid>https://blog.adipolak.com/post/delta-lake-essential-fundamentals---part-4/</guid><description>&lt;p>ðŸŽ‰ Welcome to the 4th part of Delta Lake essential fundamentals: the practical scenarios! ðŸŽ‰&lt;/p>
&lt;p>There are many great features that you can leverage in delta lake, from the ACID transaction, Schema Enforcement, Time Traveling, Exactly One semantic, and more.&lt;/p>
&lt;p>Let&amp;rsquo;s discuss two common data pipelines patterns and solutions:&lt;/p>
&lt;h2 id="spark-structured-streaming-etl-with-deltalake-that-serves-multiple-users">Spark Structured Streaming ETL with DeltaLake that serves multiple Users&lt;/h2>
&lt;p>&lt;strong>Spark Structured Streaming&lt;/strong>-
Apache Spark structured steaming are essentially unbounded tables of information. There is a continuous stream of data ingested into the system. As developers, we write the code to process the data continuously.
&lt;strong>ETL&lt;/strong> stands for &lt;strong>E&lt;/strong>xtract, &lt;strong>T&lt;/strong>ransform and &lt;strong>L&lt;/strong>oad.&lt;/p></description></item></channel></rss>