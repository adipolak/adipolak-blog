<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DeltaLog on Adi Polak</title><link>https://blog.adipolak.com/tags/deltalog/</link><description>Recent content in DeltaLog on Adi Polak</description><generator>Hugo</generator><language>en-us</language><copyright>Copyright &amp;#169; 2020 Adi Polak. All rights reserved.</copyright><lastBuildDate>Mon, 15 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.adipolak.com/tags/deltalog/index.xml" rel="self" type="application/rss+xml"/><item><title>Delta Lake essential Fundamentals: Part 3 - compaction and checkpoint</title><link>https://blog.adipolak.com/post/delta-lake-essential-fundamentals---part-3/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><guid>https://blog.adipolak.com/post/delta-lake-essential-fundamentals---part-3/</guid><description>&lt;p>Let&amp;rsquo;s understand what are Delta Lake compact and checkpoint and why they are important.&lt;/p>
&lt;h2 id="checkpoint">Checkpoint&lt;/h2>
&lt;p>There are two known checkpoints mechanism in Apache Spark that can confuse us with DeltaLake checkpoint, so let&amp;rsquo;s understand them and how they differ from each other:&lt;/p>
&lt;h3 id="spark-rdd-checkpoint">Spark RDD Checkpoint&lt;/h3>
&lt;p>Checkpoint in Spark RDD is a mechanism to persist current RDD to a file in a dedicated checkpoint directory while all references to its parent RDDs are removed.
This operation, by default, breaks data lineage when used without auditing.&lt;/p></description></item><item><title>Delta Lake essential Fundamentals: Part 2 - The DeltaLog</title><link>https://blog.adipolak.com/post/delta-lake-essential-fundamentals---the-deltalog/</link><pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate><guid>https://blog.adipolak.com/post/delta-lake-essential-fundamentals---the-deltalog/</guid><description>&lt;p>In the previous part, you learned what &lt;a href="https://blog.adipolak.com/post/delta-lake-essential-fundamentals">ACID transactions&lt;/a> are.&lt;br>
In this part, you will understand how Delta Transaction Log, named DeltaLog, is achieving ACID.&lt;/p>
&lt;h2 id="transaction-log">Transaction Log&lt;/h2>
&lt;p>A transaction log is a history of actions executed by a (TaDa ðŸ’¡) database management system with the goal to guarantee &lt;a href="https://blog.adipolak.com/post/delta-lake-essential-fundamentals/">ACID properties&lt;/a> over a crash.&lt;/p>
&lt;h2 id="deltalake-transaction-log---detlalog">DeltaLake transaction log - DetlaLog&lt;/h2>
&lt;p>DeltaLog is a transaction log directory that holds an &lt;strong>ordered&lt;/strong> record of every transaction committed on a Delta Lake table since it was created.
The goal of DeltaLog is to be the &lt;strong>single&lt;/strong> source of truth for readers who read from the same table at the same time. That means, parallel readers read the &lt;strong>exact&lt;/strong> same data.
This is achieved by tracking all the changes that users do: read, delete, update, etc. in the DeltaLog.&lt;/p></description></item></channel></rss>